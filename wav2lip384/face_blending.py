"""
ä¼˜åŒ–çš„é¢éƒ¨èåˆæ¨¡å—

é›†æˆäº†å¤šç§é«˜çº§èåˆæŠ€æœ¯:
1. LABé¢œè‰²ç©ºé—´åŒ¹é…
2. å…‰ç…§è¡¥å¿  
3. æ³Šæ¾èåˆ
4. è‡ªé€‚åº”ç¾½åŒ–
5. å¤šå°ºåº¦èåˆ
"""

import cv2
import numpy as np
import time
from typing import Tuple, Optional, Union

class FastFaceBlending:
    """å¿«é€Ÿé¢éƒ¨èåˆç±» - ä¿æŒå‘åå…¼å®¹"""
    
    def __init__(self):
        pass
    
    def fast_color_match_lab(self, source_face, target_face):
        """å¿«é€ŸLABé¢œè‰²åŒ¹é…"""
        try:
            source_lab = cv2.cvtColor(source_face, cv2.COLOR_BGR2LAB)
            target_lab = cv2.cvtColor(target_face, cv2.COLOR_BGR2LAB)
            
            source_mean = np.mean(source_lab, axis=(0, 1))
            target_mean = np.mean(target_lab, axis=(0, 1))
            
            matched_lab = source_lab.astype(np.float32)
            matched_lab += (target_mean - source_mean)
            matched_lab = np.clip(matched_lab, 0, 255)
            
            return cv2.cvtColor(matched_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
        except:
            return source_face
    
    def fast_gaussian_blend(self, source_face, target_face, landmarks=None):
        """å¿«é€Ÿé«˜æ–¯èåˆ"""
        try:
            mask = np.ones(source_face.shape[:2], dtype=np.float32)
            feather_size = min(source_face.shape[0], source_face.shape[1]) // 10
            
            if feather_size > 0:
                mask = cv2.erode(mask, np.ones((feather_size, feather_size), np.uint8))
                mask = cv2.GaussianBlur(mask, (feather_size*2+1, feather_size*2+1), feather_size/3)
            
            mask_3d = np.stack([mask] * 3, axis=2)
            return (source_face * mask_3d + target_face * (1 - mask_3d)).astype(np.uint8)
        except:
            return source_face
    
    def create_optimized_mask(self, face_shape, feather_amount=0.8):
        """åˆ›å»ºä¼˜åŒ–æ©ç """
        mask = np.ones(face_shape[:2], dtype=np.float32)
        feather_size = int(min(face_shape[0], face_shape[1]) * 0.1 * feather_amount)
        
        if feather_size > 0:
            mask = cv2.erode(mask, np.ones((feather_size, feather_size), np.uint8))
            mask = cv2.GaussianBlur(mask, (feather_size*2+1, feather_size*2+1), feather_size/3)
        
        return mask
    
    def blend_face_fast(self, source_face, target_face, landmarks=None, feather_amount=0.8):
        """å¿«é€Ÿé¢éƒ¨èåˆï¼ˆä»…é®ç½©èåˆï¼Œä¸åšè°ƒè‰²ï¼‰"""
        try:
            # åˆ›å»ºæ©ç å¹¶èåˆï¼ˆç§»é™¤é¢œè‰²åŒ¹é…ï¼Œä¿ç•™çº¯é®ç½©èåˆï¼‰
            mask = self.create_optimized_mask(source_face.shape, feather_amount)
            mask_3d = np.stack([mask] * 3, axis=2)
            result = (source_face * mask_3d + target_face * (1 - mask_3d)).astype(np.uint8)
            return result
        except Exception as e:
            print(f"å¿«é€Ÿèåˆå¤±è´¥: {e}")
            return target_face

class ImprovedFaceBlending:
    """æ”¹è¿›çš„é¢éƒ¨èåˆç±» - è§£å†³é»‘è¾¹é—®é¢˜"""

    def __init__(self):
        """åˆå§‹åŒ–æ”¹è¿›çš„é¢éƒ¨èåˆå™¨"""
        # åŠŸèƒ½å¼€å…³ï¼ˆé»˜è®¤ç¦ç”¨è°ƒè‰²ä¸æ³Šæ¾èåˆï¼Œé‡‡ç”¨çº¯é®ç½©èåˆï¼‰
        self.enable_poisson = False
        self.enable_color_matching = False
        self.enable_edge_smoothing = True
        self.enable_noise_reduction = True
        
        # åŸæœ‰å‚æ•°
        self.color_match_enabled = True
        self.lighting_compensation = True
        self.adaptive_feathering = True
        self.multi_scale_blending = True
        
        # 384æ¨¡å‹ä¸“ç”¨å‚æ•°
        self.feather_ratio_384 = 0.08  # ç¾½åŒ–èŒƒå›´æ¯”ä¾‹
        self.min_feather_size = 8      # æœ€å°ç¾½åŒ–å°ºå¯¸
        self.max_feather_size = 25     # æœ€å¤§ç¾½åŒ–å°ºå¯¸
        
        # é¢œè‰²ç›¸å…³å‚æ•°ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å ä½é¿å…å¤–éƒ¨å¼•ç”¨æŠ¥é”™
        self.saturation_factor = 0.0
        self.color_blend_ratio = 0.0
        self.max_saturation_boost = 1.0
        self.saturation_preservation = 1.0
        self.brightness_threshold = 0
        self.max_brightness_adjustment = 1.0
        
    def blend_face(self, pred_frame: np.ndarray, original_frame: np.ndarray,
                   bbox: Tuple[int, int, int, int],
                   feather_amount: float = 0.8) -> Optional[np.ndarray]:
        """
        é¢éƒ¨èåˆï¼ˆä»…é®ç½©èåˆï¼Œä¸åšä»»ä½•è°ƒè‰²/å…‰ç…§è¡¥å¿/æ³Šæ¾èåˆï¼‰
        """
        try:
            y1, y2, x1, x2 = bbox
            # éªŒè¯è¾“å…¥
            if not self._validate_inputs(pred_frame, original_frame, bbox):
                return None
            # è°ƒæ•´é¢„æµ‹é¢éƒ¨å°ºå¯¸
            target_width = x2 - x1
            target_height = y2 - y1
            resized_pred = cv2.resize(pred_frame, (target_width, target_height),
                                      interpolation=cv2.INTER_LANCZOS4)
            # ä»…ä½¿ç”¨é«˜æ–¯/è·ç¦»å˜æ¢çš„é®ç½©èåˆï¼Œä¿æŒåŸè§†é¢‘é¢œè‰²ä¸€è‡´æ€§
            result = self._advanced_gaussian_blend(resized_pred, original_frame, bbox, feather_amount)
            return result
        except Exception as e:
            print(f"èåˆå¤±è´¥: {e}")
            return None
    
    def _validate_inputs(self, pred_frame: np.ndarray, original_frame: np.ndarray, 
                        bbox: Tuple[int, int, int, int]) -> bool:
        """éªŒè¯è¾“å…¥å‚æ•°"""
        y1, y2, x1, x2 = bbox
        
        # æ£€æŸ¥è¾¹ç•Œæ¡†
        if (y1 >= y2 or x1 >= x2 or 
            y1 < 0 or x1 < 0 or 
            y2 > original_frame.shape[0] or 
            x2 > original_frame.shape[1]):
            return False
        
        # æ£€æŸ¥å›¾åƒ
        if pred_frame is None or original_frame is None:
            return False
        
        if len(pred_frame.shape) != 3 or len(original_frame.shape) != 3:
            return False
        
        return True
    
    def _match_colors_lab(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                         bbox: Tuple[int, int, int, int]) -> np.ndarray:
        """LABé¢œè‰²ç©ºé—´åŒ¹é… - è§£å†³é¢œè‰²ä¸ä¸€è‡´"""
        try:
            y1, y2, x1, x2 = bbox
            
            # è½¬æ¢åˆ°LABé¢œè‰²ç©ºé—´
            pred_lab = cv2.cvtColor(pred_face, cv2.COLOR_BGR2LAB)
            
            # è·å–å‘¨å›´åŒºåŸŸç”¨äºé¢œè‰²å‚è€ƒ
            margin = min(20, (y2-y1)//4, (x2-x1)//4)
            
            # æ‰©å±•åŒºåŸŸè·å–æ›´å¤šä¸Šä¸‹æ–‡
            ref_y1 = max(0, y1 - margin)
            ref_y2 = min(original_frame.shape[0], y2 + margin)
            ref_x1 = max(0, x1 - margin)
            ref_x2 = min(original_frame.shape[1], x2 + margin)
            
            reference_region = original_frame[ref_y1:ref_y2, ref_x1:ref_x2]
            ref_lab = cv2.cvtColor(reference_region, cv2.COLOR_BGR2LAB)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            pred_mean = np.mean(pred_lab, axis=(0, 1))
            pred_std = np.std(pred_lab, axis=(0, 1))
            
            ref_mean = np.mean(ref_lab, axis=(0, 1))
            ref_std = np.std(ref_lab, axis=(0, 1))
            
            # é¢œè‰²åŒ¹é… - åªè°ƒæ•´Aå’ŒBé€šé“ï¼ˆè‰²å½©ï¼‰ï¼Œä¿æŒLé€šé“ï¼ˆäº®åº¦ï¼‰ç›¸å¯¹ç¨³å®š
            matched_lab = pred_lab.astype(np.float32)
            
            for i in range(3):
                if pred_std[i] > 0:
                    if i == 0:  # Lé€šé“ - è½»å¾®è°ƒæ•´
                        matched_lab[:, :, i] = (matched_lab[:, :, i] - pred_mean[i]) * 0.7 * (ref_std[i] / pred_std[i]) + ref_mean[i] * 0.3 + pred_mean[i] * 0.7
                    else:  # A, Bé€šé“ - å®Œå…¨åŒ¹é…
                        matched_lab[:, :, i] = (matched_lab[:, :, i] - pred_mean[i]) * (ref_std[i] / pred_std[i]) + ref_mean[i]
            
            # é™åˆ¶èŒƒå›´
            matched_lab = np.clip(matched_lab, 0, 255)
            
            # è½¬æ¢å›BGR
            matched_bgr = cv2.cvtColor(matched_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            
            return matched_bgr
            
        except Exception as e:
            print(f"é¢œè‰²åŒ¹é…å¤±è´¥: {e}")
            return pred_face
    
    def _gentle_edge_smoothing(self, adjusted_face: np.ndarray, original_face: np.ndarray, 
                              strength: float = 0.15) -> np.ndarray:
        """æ¸©å’Œçš„è¾¹ç¼˜å¹³æ»‘å¤„ç†"""
        try:
            h, w = adjusted_face.shape[:2]
            edge_width = max(3, min(8, h//20, w//20))  # å¾ˆå°çš„è¾¹ç¼˜å®½åº¦
            
            # åˆ›å»ºè¾¹ç¼˜æ©ç 
            mask = np.ones((h, w), dtype=np.float32)
            mask[:edge_width, :] = 0
            mask[-edge_width:, :] = 0
            mask[:, :edge_width] = 0
            mask[:, -edge_width:] = 0
            
            # è·ç¦»å˜æ¢åˆ›å»ºå¹³æ»‘è¿‡æ¸¡
            dist_transform = cv2.distanceTransform((mask > 0).astype(np.uint8), cv2.DIST_L2, 3)
            edge_mask = np.clip(dist_transform / edge_width, 0, 1)
            
            # åº”ç”¨éå¸¸æ¸©å’Œçš„å¼ºåº¦
            edge_mask = np.power(edge_mask, 0.8) * strength + (1 - strength)
            edge_mask_3d = np.stack([edge_mask] * 3, axis=2)
            
            # æ¸©å’Œèåˆ
            result = adjusted_face * edge_mask_3d + original_face * (1 - edge_mask_3d)
            return result.astype(np.uint8)
            
        except Exception as e:
            print(f"æ¸©å’Œè¾¹ç¼˜å¹³æ»‘å¤±è´¥: {e}")
            return adjusted_face

    
    def _compensate_lighting(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                           bbox: Tuple[int, int, int, int]) -> np.ndarray:
        """å…‰ç…§è¡¥å¿"""
        try:
            y1, y2, x1, x2 = bbox
            
            # è®¡ç®—å‘¨å›´åŒºåŸŸçš„å¹³å‡äº®åº¦
            margin = min(15, (y2-y1)//6, (x2-x1)//6)
            
            surrounding_regions = []
            
            # ä¸Šæ–¹
            if y1 >= margin:
                surrounding_regions.append(original_frame[y1-margin:y1, x1:x2])
            
            # ä¸‹æ–¹
            if y2 + margin < original_frame.shape[0]:
                surrounding_regions.append(original_frame[y2:y2+margin, x1:x2])
            
            # å·¦ä¾§
            if x1 >= margin:
                surrounding_regions.append(original_frame[y1:y2, x1-margin:x1])
            
            # å³ä¾§
            if x2 + margin < original_frame.shape[1]:
                surrounding_regions.append(original_frame[y1:y2, x2:x2+margin])
            
            if not surrounding_regions:
                return pred_face
            
            # è®¡ç®—å‘¨å›´äº®åº¦
            surrounding_brightness = np.mean([np.mean(cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)) 
                                            for region in surrounding_regions])
            
            # è®¡ç®—é¢éƒ¨äº®åº¦
            face_brightness = np.mean(cv2.cvtColor(pred_face, cv2.COLOR_BGR2GRAY))
            
            # å…‰ç…§è¡¥å¿
            if abs(surrounding_brightness - face_brightness) > 10:
                brightness_ratio = surrounding_brightness / (face_brightness + 1e-6)
                brightness_ratio = np.clip(brightness_ratio, 0.7, 1.3)  # é™åˆ¶è°ƒæ•´èŒƒå›´
                
                compensated = pred_face.astype(np.float32) * brightness_ratio
                compensated = np.clip(compensated, 0, 255).astype(np.uint8)
                
                return compensated
            
            return pred_face
            
        except Exception as e:
            print(f"å…‰ç…§è¡¥å¿å¤±è´¥: {e}")
            return pred_face
    
    def _progressive_lab_adjustment(self, pred_face: np.ndarray, reference_region: np.ndarray, 
                                  diff_analysis: dict, strength: float = 0.3) -> np.ndarray:
        """æ¸è¿›å¼LABç©ºé—´è°ƒæ•´"""
        try:
            pred_lab = cv2.cvtColor(pred_face, cv2.COLOR_BGR2LAB).astype(np.float32)
            ref_lab = cv2.cvtColor(reference_region, cv2.COLOR_BGR2LAB)
            
            pred_mean = np.mean(pred_lab, axis=(0, 1))
            ref_mean = np.mean(ref_lab, axis=(0, 1))
            
            # æ ¹æ®åˆ†æç»“æœå’Œå¼ºåº¦å‚æ•°è°ƒæ•´å„é€šé“
            lightness_strength = min(strength, diff_analysis['lightness_diff'] / 100.0)
            chroma_strength = min(strength * 0.8, diff_analysis['chroma_diff'] / 80.0)
            
            # éå¸¸ä¿å®ˆçš„è°ƒæ•´
            pred_lab[:, :, 0] += (ref_mean[0] - pred_mean[0]) * lightness_strength
            pred_lab[:, :, 1] += (ref_mean[1] - pred_mean[1]) * chroma_strength
            pred_lab[:, :, 2] += (ref_mean[2] - pred_mean[2]) * chroma_strength
            
            # é™åˆ¶èŒƒå›´
            pred_lab[:, :, 0] = np.clip(pred_lab[:, :, 0], 0, 100)
            pred_lab[:, :, 1] = np.clip(pred_lab[:, :, 1], -128, 127)
            pred_lab[:, :, 2] = np.clip(pred_lab[:, :, 2], -128, 127)
            
            return cv2.cvtColor(pred_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            
        except Exception as e:
            print(f"æ¸è¿›å¼LABè°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _progressive_hsv_adjustment(self, pred_face: np.ndarray, reference_region: np.ndarray, 
                                 diff_analysis: dict, strength: float = 0.2) -> np.ndarray:
        """æ¸è¿›å¼HSVç©ºé—´è°ƒæ•´"""
        try:
            pred_hsv = cv2.cvtColor(pred_face, cv2.COLOR_BGR2HSV).astype(np.float32)
            ref_hsv = cv2.cvtColor(reference_region, cv2.COLOR_BGR2HSV)
            
            pred_mean = np.mean(pred_hsv, axis=(0, 1))
            ref_mean = np.mean(ref_hsv, axis=(0, 1))
            
            # è‰²è°ƒè°ƒæ•´ï¼ˆè€ƒè™‘ç¯å½¢ç‰¹æ€§ï¼‰
            h_diff = ref_mean[0] - pred_mean[0]
            if abs(h_diff) > 90:
                h_diff = h_diff - 180 if h_diff > 0 else h_diff + 180
            
            hue_strength = min(strength * 0.6, diff_analysis['hue_diff'] / 60.0)
            saturation_strength = min(strength * 0.8, diff_analysis['saturation_diff'] / 80.0)
            
            # éå¸¸ä¿å®ˆçš„è°ƒæ•´
            pred_hsv[:, :, 0] = (pred_hsv[:, :, 0] + h_diff * hue_strength) % 180
            pred_hsv[:, :, 1] += (ref_mean[1] - pred_mean[1]) * saturation_strength
            
            # é™åˆ¶èŒƒå›´
            pred_hsv[:, :, 1] = np.clip(pred_hsv[:, :, 1], 0, 255)
            pred_hsv[:, :, 2] = np.clip(pred_hsv[:, :, 2], 0, 255)
            
            return cv2.cvtColor(pred_hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
            
        except Exception as e:
            print(f"æ¸è¿›å¼HSVè°ƒæ•´å¤±è´¥: {e}")
            return pred_face

    
    def _blend_with_best_method(self, pred_face: np.ndarray, original_frame: np.ndarray,
                                bbox: Tuple[int, int, int, int], feather_amount: float) -> np.ndarray:
        """é€‰æ‹©èåˆæ–¹æ³•ï¼ˆå·²ç»Ÿä¸€ä¸ºé®ç½©èåˆï¼‰"""
        return self._advanced_gaussian_blend(pred_face, original_frame, bbox, feather_amount)
    
    def _poisson_blend(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                      bbox: Tuple[int, int, int, int]) -> Optional[np.ndarray]:
        """æ³Šæ¾èåˆ - æœ€ä½³æ•ˆæœ"""
        try:
            y1, y2, x1, x2 = bbox
            
            # åˆ›å»ºæ©ç 
            mask = np.ones((y2-y1, x2-x1), dtype=np.uint8) * 255
            
            # æ”¶ç¼©æ©ç è¾¹ç¼˜ä»¥é¿å…è¾¹ç•Œé—®é¢˜
            kernel_size = max(3, min(7, (y2-y1)//20, (x2-x1)//20))
            if kernel_size >= 3:
                kernel = np.ones((kernel_size, kernel_size), np.uint8)
                mask = cv2.erode(mask, kernel, iterations=1)
            
            # ä¸­å¿ƒç‚¹
            center = ((x1 + x2) // 2, (y1 + y2) // 2)
            
            # æ³Šæ¾èåˆ
            result = cv2.seamlessClone(pred_face, original_frame, mask, center, cv2.NORMAL_CLONE)
            
            return result
            
        except Exception as e:
            print(f"æ³Šæ¾èåˆå¤±è´¥: {e}")
            return None
    
    def _advanced_gaussian_blend(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                bbox: Tuple[int, int, int, int], feather_amount: float) -> np.ndarray:
        """é«˜çº§é«˜æ–¯èåˆ - å¤‡ç”¨æ–¹æ¡ˆ"""
        y1, y2, x1, x2 = bbox
        result = original_frame.copy()
        
        # è®¡ç®—è‡ªé€‚åº”ç¾½åŒ–å°ºå¯¸
        face_width = x2 - x1
        face_height = y2 - y1
        
        if self.adaptive_feathering:
            # åŸºäºé¢éƒ¨å°ºå¯¸çš„è‡ªé€‚åº”ç¾½åŒ–
            feather_size = int(min(face_width, face_height) * self.feather_ratio_384 * feather_amount)
            feather_size = max(self.min_feather_size, min(self.max_feather_size, feather_size))
        else:
            feather_size = int(15 * feather_amount)
        
        # åˆ›å»ºè·ç¦»å˜æ¢æ©ç 
        mask = np.ones((face_height, face_width), dtype=np.float32)
        
        if feather_size > 0:
            # ä½¿ç”¨è·ç¦»å˜æ¢åˆ›å»ºæ›´å¹³æ»‘çš„æ©ç 
            border_mask = np.zeros((face_height, face_width), dtype=np.uint8)
            border_mask[feather_size:-feather_size, feather_size:-feather_size] = 255
            
            # è·ç¦»å˜æ¢
            dist_transform = cv2.distanceTransform(border_mask, cv2.DIST_L2, 5)
            
            # å½’ä¸€åŒ–åˆ°0-1
            if np.max(dist_transform) > 0:
                mask = np.clip(dist_transform / feather_size, 0, 1)
            
            # åº”ç”¨é«˜æ–¯å¹³æ»‘
            mask = cv2.GaussianBlur(mask, (feather_size*2+1, feather_size*2+1), feather_size/3)
        
        # æ ‡å‡†èåˆ
        mask_3d = np.stack([mask] * 3, axis=2)
        blended_region = (pred_face * mask_3d + 
                        original_frame[y1:y2, x1:x2] * (1 - mask_3d))
        result[y1:y2, x1:x2] = blended_region.astype(np.uint8)
        
        return result

    
    def _match_colors_lab_balanced(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                 bbox: Tuple[int, int, int, int]) -> np.ndarray:
        """è‡ªé€‚åº”é¢œè‰²åŒ¹é…ç®—æ³• - æ ¹æ®è‰²å·®ç¨‹åº¦é€‰æ‹©æœ€ä½³ç­–ç•¥"""
        try:
            y1, y2, x1, x2 = bbox
            
            # 1. åˆ†æé¢œè‰²å·®å¼‚ç¨‹åº¦
            diff_analysis = self._analyze_color_difference_severity(pred_face, original_frame, bbox)
            
            total_score = diff_analysis['total_score']
            dominant_issue = diff_analysis['dominant_issue']
            
            print(f"ğŸ¨ è‰²å·®åˆ†æ: æ€»åˆ†={total_score:.1f}, ä¸»è¦é—®é¢˜={dominant_issue}")
            
            # 2. æ ¹æ®è‰²å·®ç¨‹åº¦å’Œç±»å‹é€‰æ‹©ç­–ç•¥
            if total_score < 15:  # è½»å¾®è‰²å·® - æœ€å°è°ƒæ•´
                print("   ç­–ç•¥: æœ€å°è°ƒæ•´")
                return self._minimal_color_adjustment(pred_face, original_frame, bbox, diff_analysis)
            elif total_score < 40:  # ä¸­ç­‰è‰²å·® - é’ˆå¯¹æ€§è°ƒæ•´
                print("   ç­–ç•¥: é’ˆå¯¹æ€§è°ƒæ•´")
                return self._targeted_color_adjustment(pred_face, original_frame, bbox, diff_analysis)
            else:  # ä¸¥é‡è‰²å·® - å¼ºåŒ–è°ƒæ•´
                print("   ç­–ç•¥: å¼ºåŒ–è°ƒæ•´")
                return self._enhanced_color_adjustment(pred_face, original_frame, bbox, diff_analysis)
            
        except Exception as e:
            print(f"é¢œè‰²åŒ¹é…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return pred_face
    
    def _analyze_color_difference_severity(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                          bbox: Tuple[int, int, int, int]) -> dict:
        """åˆ†æé¢œè‰²å·®å¼‚ä¸¥é‡ç¨‹åº¦ - ä½¿ç”¨æ›´ç§‘å­¦çš„æ–¹æ³•"""
        try:
            y1, y2, x1, x2 = bbox
            
            # è·å–å‚è€ƒåŒºåŸŸ
            margin = min(20, (y2-y1)//4, (x2-x1)//4)
            ref_y1 = max(0, y1 - margin)
            ref_y2 = min(original_frame.shape[0], y2 + margin)
            ref_x1 = max(0, x1 - margin)
            ref_x2 = min(original_frame.shape[1], x2 + margin)
            
            reference_region = original_frame[ref_y1:ref_y2, ref_x1:ref_x2]
            
            # å¤šé¢œè‰²ç©ºé—´åˆ†æ
            pred_lab = cv2.cvtColor(pred_face, cv2.COLOR_BGR2LAB).astype(np.float32)
            ref_lab = cv2.cvtColor(reference_region, cv2.COLOR_BGR2LAB).astype(np.float32)
            
            pred_hsv = cv2.cvtColor(pred_face, cv2.COLOR_BGR2HSV).astype(np.float32)
            ref_hsv = cv2.cvtColor(reference_region, cv2.COLOR_BGR2HSV).astype(np.float32)
            
            # è®¡ç®—å„é€šé“å·®å¼‚
            pred_lab_mean = np.mean(pred_lab, axis=(0, 1))
            ref_lab_mean = np.mean(ref_lab, axis=(0, 1))
            
            pred_hsv_mean = np.mean(pred_hsv, axis=(0, 1))
            ref_hsv_mean = np.mean(ref_hsv, axis=(0, 1))
            
            # 1. äº®åº¦å·®å¼‚ (LAB Lé€šé“)
            lightness_diff = abs(pred_lab_mean[0] - ref_lab_mean[0])
            
            # 2. è‰²åº¦å·®å¼‚ (LAB a,bé€šé“)
            chroma_diff = np.sqrt((pred_lab_mean[1] - ref_lab_mean[1])**2 + 
                                (pred_lab_mean[2] - ref_lab_mean[2])**2)
            
            # 3. è‰²è°ƒå·®å¼‚ (HSV Hé€šé“ï¼Œè€ƒè™‘ç¯å½¢ç‰¹æ€§)
            h_diff = abs(pred_hsv_mean[0] - ref_hsv_mean[0])
            h_diff = min(h_diff, 180 - h_diff)  # å¤„ç†è‰²è°ƒç¯å½¢ç‰¹æ€§
            
            # 4. é¥±å’Œåº¦å·®å¼‚ (HSV Sé€šé“)
            saturation_diff = abs(pred_hsv_mean[1] - ref_hsv_mean[1])
            
            # 5. è®¡ç®—ç±»ä¼¼Delta Eçš„ç»¼åˆè‰²å·®
            delta_e = np.sqrt(lightness_diff**2 + chroma_diff**2)
            
            # 6. åˆ†æè‰²å·®ç±»å‹
            diff_analysis = {
                'total_score': delta_e,
                'lightness_diff': lightness_diff,
                'chroma_diff': chroma_diff,
                'hue_diff': h_diff,
                'saturation_diff': saturation_diff,
                'dominant_issue': self._identify_dominant_color_issue(
                    lightness_diff, chroma_diff, h_diff, saturation_diff
                )
            }
            
            return diff_analysis
            
        except Exception as e:
            print(f"è‰²å·®åˆ†æå¤±è´¥: {e}")
            return {
                'total_score': 50.0,
                'lightness_diff': 25.0,
                'chroma_diff': 25.0,
                'hue_diff': 15.0,
                'saturation_diff': 20.0,
                'dominant_issue': 'unknown'
            }
    
    def _identify_dominant_color_issue(self, lightness_diff: float, chroma_diff: float, 
                                     hue_diff: float, saturation_diff: float) -> str:
        """è¯†åˆ«ä¸»è¦çš„é¢œè‰²é—®é¢˜ç±»å‹"""
        issues = {
            'lightness': lightness_diff,
            'chroma': chroma_diff,
            'hue': hue_diff * 2.0,  # è‰²è°ƒå·®å¼‚æƒé‡æ›´é«˜
            'saturation': saturation_diff
        }
        
        dominant_issue = max(issues, key=issues.get)
        return dominant_issue
    
    def _minimal_color_adjustment(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                bbox: Tuple[int, int, int, int], diff_analysis: dict) -> np.ndarray:
        """æœ€å°é¢œè‰²è°ƒæ•´ - ä»…å¾®è°ƒäº®åº¦"""
        try:
            y1, y2, x1, x2 = bbox
            
            # è·å–å‚è€ƒåŒºåŸŸ
            margin = min(15, (y2-y1)//6, (x2-x1)//6)
            ref_y1 = max(0, y1 - margin)
            ref_y2 = min(original_frame.shape[0], y2 + margin)
            ref_x1 = max(0, x1 - margin)
            ref_x2 = min(original_frame.shape[1], x2 + margin)
            
            reference_region = original_frame[ref_y1:ref_y2, ref_x1:ref_x2]
            
            # ä»…åœ¨LABç©ºé—´è°ƒæ•´Lé€šé“ï¼ˆäº®åº¦ï¼‰
            pred_lab = cv2.cvtColor(pred_face, cv2.COLOR_BGR2LAB).astype(np.float32)
            ref_lab = cv2.cvtColor(reference_region, cv2.COLOR_BGR2LAB)
            
            pred_l_mean = np.mean(pred_lab[:, :, 0])
            ref_l_mean = np.mean(ref_lab[:, :, 0])
            
            # æ ¹æ®å·®å¼‚ç¨‹åº¦è°ƒæ•´å¼ºåº¦
            lightness_diff = diff_analysis.get('lightness_diff', abs(pred_l_mean - ref_l_mean))
            adjustment_strength = min(0.8, lightness_diff / 50.0)
            
            l_adjustment = (ref_l_mean - pred_l_mean) * adjustment_strength
            pred_lab[:, :, 0] = np.clip(pred_lab[:, :, 0] + l_adjustment, 0, 255)
            
            return cv2.cvtColor(pred_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            
        except Exception as e:
            print(f"æœ€å°é¢œè‰²è°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _targeted_color_adjustment(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                 bbox: Tuple[int, int, int, int], diff_analysis: dict) -> np.ndarray:
        """é’ˆå¯¹æ€§é¢œè‰²è°ƒæ•´ - æ ¹æ®ä¸»è¦é—®é¢˜ç±»å‹è¿›è¡Œè°ƒæ•´"""
        try:
            dominant_issue = diff_analysis['dominant_issue']
            
            if dominant_issue == 'lightness':
                return self._adjust_lightness_focused(pred_face, original_frame, bbox, diff_analysis)
            elif dominant_issue == 'hue':
                return self._adjust_hue_focused(pred_face, original_frame, bbox, diff_analysis)
            elif dominant_issue == 'saturation':
                return self._adjust_saturation_focused(pred_face, original_frame, bbox, diff_analysis)
            else:  # chroma or unknown
                return self._adjust_chroma_focused(pred_face, original_frame, bbox, diff_analysis)
                
        except Exception as e:
            print(f"é’ˆå¯¹æ€§é¢œè‰²è°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _enhanced_color_adjustment(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                 bbox: Tuple[int, int, int, int], diff_analysis: dict) -> np.ndarray:
        """å¼ºåŒ–é¢œè‰²è°ƒæ•´ - ç”¨äºä¸¥é‡è‰²å·®åœºæ™¯ï¼Œé‡‡ç”¨æ¸è¿›å¼ä¿å®ˆè°ƒæ•´"""
        try:
            y1, y2, x1, x2 = bbox
            
            # è·å–å‚è€ƒåŒºåŸŸ
            margin = min(25, (y2-y1)//3, (x2-x1)//3)
            ref_y1 = max(0, y1 - margin)
            ref_y2 = min(original_frame.shape[0], y2 + margin)
            ref_x1 = max(0, x1 - margin)
            ref_x2 = min(original_frame.shape[1], x2 + margin)
            
            reference_region = original_frame[ref_y1:ref_y2, ref_x1:ref_x2]
            
            # æ¸è¿›å¼è°ƒæ•´ç­–ç•¥ - æ¯æ­¥éƒ½å¾ˆä¿å®ˆï¼Œé¿å…è¿‡åº¦è°ƒæ•´
            adjusted_face = pred_face.copy()
            
            # 1. ç¬¬ä¸€æ­¥ï¼šéå¸¸æ¸©å’Œçš„LABè°ƒæ•´ï¼ˆå¤§å¹…é™ä½å¼ºåº¦ï¼‰
            adjusted_face = self._progressive_lab_adjustment(adjusted_face, reference_region, diff_analysis, strength=0.3)
            
            # 2. ç¬¬äºŒæ­¥ï¼šæœ‰é€‰æ‹©æ€§çš„HSVå¾®è°ƒ
            if diff_analysis['dominant_issue'] in ['hue', 'saturation']:
                adjusted_face = self._progressive_hsv_adjustment(adjusted_face, reference_region, diff_analysis, strength=0.2)
            
            # 3. ç¬¬ä¸‰æ­¥ï¼šæè½»åº¦çš„è¾¹ç¼˜èåˆ
            adjusted_face = self._gentle_edge_smoothing(adjusted_face, pred_face, strength=0.15)
            
            # 4. ç¬¬å››æ­¥ï¼šæœ€å°åŒ–çš„è‚¤è‰²è‡ªç„¶åŒ–
            adjusted_face = self._skin_tone_naturalization_gentle(adjusted_face)
            
            return adjusted_face
            
        except Exception as e:
            print(f"å¼ºåŒ–é¢œè‰²è°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _adjust_lightness_focused(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                bbox: Tuple[int, int, int, int], diff_analysis: dict) -> np.ndarray:
        """ä¸“æ³¨äºäº®åº¦è°ƒæ•´"""
        try:
            y1, y2, x1, x2 = bbox
            margin = min(20, (y2-y1)//4, (x2-x1)//4)
            ref_y1 = max(0, y1 - margin)
            ref_y2 = min(original_frame.shape[0], y2 + margin)
            ref_x1 = max(0, x1 - margin)
            ref_x2 = min(original_frame.shape[1], x2 + margin)
            
            reference_region = original_frame[ref_y1:ref_y2, ref_x1:ref_x2]
            
            # LABç©ºé—´äº®åº¦è°ƒæ•´
            pred_lab = cv2.cvtColor(pred_face, cv2.COLOR_BGR2LAB).astype(np.float32)
            ref_lab = cv2.cvtColor(reference_region, cv2.COLOR_BGR2LAB)
            
            pred_l_mean = np.mean(pred_lab[:, :, 0])
            ref_l_mean = np.mean(ref_lab[:, :, 0])
            
            # æ ¹æ®å·®å¼‚ç¨‹åº¦è°ƒæ•´å¼ºåº¦
            lightness_diff = diff_analysis['lightness_diff']
            adjustment_strength = min(0.8, lightness_diff / 50.0)
            
            l_adjustment = (ref_l_mean - pred_l_mean) * adjustment_strength
            pred_lab[:, :, 0] = np.clip(pred_lab[:, :, 0] + l_adjustment, 0, 100)
            
            return cv2.cvtColor(pred_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            
        except Exception as e:
            print(f"äº®åº¦è°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _adjust_hue_focused(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                          bbox: Tuple[int, int, int, int], diff_analysis: dict) -> np.ndarray:
        """ä¸“æ³¨äºè‰²è°ƒè°ƒæ•´"""
        try:
            y1, y2, x1, x2 = bbox
            margin = min(20, (y2-y1)//4, (x2-x1)//4)
            ref_y1 = max(0, y1 - margin)
            ref_y2 = min(original_frame.shape[0], y2 + margin)
            ref_x1 = max(0, x1 - margin)
            ref_x2 = min(original_frame.shape[1], x2 + margin)
            
            reference_region = original_frame[ref_y1:ref_y2, ref_x1:ref_x2]
            
            # HSVç©ºé—´è‰²è°ƒè°ƒæ•´
            pred_hsv = cv2.cvtColor(pred_face, cv2.COLOR_BGR2HSV).astype(np.float32)
            ref_hsv = cv2.cvtColor(reference_region, cv2.COLOR_BGR2HSV)
            
            pred_h_mean = np.mean(pred_hsv[:, :, 0])
            ref_h_mean = np.mean(ref_hsv[:, :, 0])
            
            # å¤„ç†è‰²è°ƒç¯å½¢ç‰¹æ€§
            h_diff = ref_h_mean - pred_h_mean
            if abs(h_diff) > 90:
                h_diff = h_diff - 180 if h_diff > 0 else h_diff + 180
            
            # æ ¹æ®å·®å¼‚ç¨‹åº¦è°ƒæ•´å¼ºåº¦
            hue_diff = diff_analysis['hue_diff']
            adjustment_strength = min(0.6, hue_diff / 30.0)
            
            h_adjustment = h_diff * adjustment_strength
            pred_hsv[:, :, 0] = (pred_hsv[:, :, 0] + h_adjustment) % 180
            
            return cv2.cvtColor(pred_hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
            
        except Exception as e:
            print(f"è‰²è°ƒè°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _adjust_saturation_focused(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                 bbox: Tuple[int, int, int, int], diff_analysis: dict) -> np.ndarray:
        """ä¸“æ³¨äºé¥±å’Œåº¦è°ƒæ•´"""
        try:
            y1, y2, x1, x2 = bbox
            margin = min(20, (y2-y1)//4, (x2-x1)//4)
            ref_y1 = max(0, y1 - margin)
            ref_y2 = min(original_frame.shape[0], y2 + margin)
            ref_x1 = max(0, x1 - margin)
            ref_x2 = min(original_frame.shape[1], x2 + margin)
            
            reference_region = original_frame[ref_y1:ref_y2, ref_x1:ref_x2]
            
            # HSVç©ºé—´é¥±å’Œåº¦è°ƒæ•´
            pred_hsv = cv2.cvtColor(pred_face, cv2.COLOR_BGR2HSV).astype(np.float32)
            ref_hsv = cv2.cvtColor(reference_region, cv2.COLOR_BGR2HSV)
            
            pred_s_mean = np.mean(pred_hsv[:, :, 1])
            ref_s_mean = np.mean(ref_hsv[:, :, 1])
            
            # æ ¹æ®å·®å¼‚ç¨‹åº¦è°ƒæ•´å¼ºåº¦
            saturation_diff = diff_analysis['saturation_diff']
            adjustment_strength = min(0.7, saturation_diff / 40.0)
            
            s_adjustment = (ref_s_mean - pred_s_mean) * adjustment_strength
            pred_hsv[:, :, 1] = np.clip(pred_hsv[:, :, 1] + s_adjustment, 0, 255)
            
            return cv2.cvtColor(pred_hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
            
        except Exception as e:
            print(f"é¥±å’Œåº¦è°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _adjust_chroma_focused(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                             bbox: Tuple[int, int, int, int], diff_analysis: dict) -> np.ndarray:
        """ä¸“æ³¨äºè‰²åº¦è°ƒæ•´"""
        try:
            y1, y2, x1, x2 = bbox
            margin = min(20, (y2-y1)//4, (x2-x1)//4)
            ref_y1 = max(0, y1 - margin)
            ref_y2 = min(original_frame.shape[0], y2 + margin)
            ref_x1 = max(0, x1 - margin)
            ref_x2 = min(original_frame.shape[1], x2 + margin)
            
            reference_region = original_frame[ref_y1:ref_y2, ref_x1:ref_x2]
            
            # LABç©ºé—´è‰²åº¦è°ƒæ•´
            pred_lab = cv2.cvtColor(pred_face, cv2.COLOR_BGR2LAB).astype(np.float32)
            ref_lab = cv2.cvtColor(reference_region, cv2.COLOR_BGR2LAB)
            
            pred_a_mean = np.mean(pred_lab[:, :, 1])
            pred_b_mean = np.mean(pred_lab[:, :, 2])
            ref_a_mean = np.mean(ref_lab[:, :, 1])
            ref_b_mean = np.mean(ref_lab[:, :, 2])
            
            # æ ¹æ®å·®å¼‚ç¨‹åº¦è°ƒæ•´å¼ºåº¦
            chroma_diff = diff_analysis['chroma_diff']
            adjustment_strength = min(0.6, chroma_diff / 30.0)
            
            a_adjustment = (ref_a_mean - pred_a_mean) * adjustment_strength
            b_adjustment = (ref_b_mean - pred_b_mean) * adjustment_strength
            
            pred_lab[:, :, 1] = np.clip(pred_lab[:, :, 1] + a_adjustment, -128, 127)
            pred_lab[:, :, 2] = np.clip(pred_lab[:, :, 2] + b_adjustment, -128, 127)
            
            return cv2.cvtColor(pred_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            
        except Exception as e:
            print(f"è‰²åº¦è°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _enhanced_lab_adjustment(self, pred_face: np.ndarray, reference_region: np.ndarray, 
                               diff_analysis: dict) -> np.ndarray:
        """å¼ºåŒ–LABç©ºé—´è°ƒæ•´"""
        try:
            pred_lab = cv2.cvtColor(pred_face, cv2.COLOR_BGR2LAB).astype(np.float32)
            ref_lab = cv2.cvtColor(reference_region, cv2.COLOR_BGR2LAB)
            
            pred_mean = np.mean(pred_lab, axis=(0, 1))
            ref_mean = np.mean(ref_lab, axis=(0, 1))
            
            # æ ¹æ®åˆ†æç»“æœè°ƒæ•´å„é€šé“å¼ºåº¦
            lightness_strength = min(0.8, diff_analysis['lightness_diff'] / 40.0)
            chroma_strength = min(0.7, diff_analysis['chroma_diff'] / 35.0)
            
            # è°ƒæ•´å„é€šé“
            pred_lab[:, :, 0] += (ref_mean[0] - pred_mean[0]) * lightness_strength
            pred_lab[:, :, 1] += (ref_mean[1] - pred_mean[1]) * chroma_strength
            pred_lab[:, :, 2] += (ref_mean[2] - pred_mean[2]) * chroma_strength
            
            # é™åˆ¶èŒƒå›´
            pred_lab[:, :, 0] = np.clip(pred_lab[:, :, 0], 0, 100)
            pred_lab[:, :, 1] = np.clip(pred_lab[:, :, 1], -128, 127)
            pred_lab[:, :, 2] = np.clip(pred_lab[:, :, 2], -128, 127)
            
            return cv2.cvtColor(pred_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            
        except Exception as e:
            print(f"å¼ºåŒ–LABè°ƒæ•´å¤±è´¥: {e}")
            return pred_face
    
    def _enhanced_hsv_adjustment(self, pred_face: np.ndarray, reference_region: np.ndarray, 
                               diff_analysis: dict) -> np.ndarray:
        """å¼ºåŒ–HSVç©ºé—´è°ƒæ•´"""
        try:
            pred_hsv = cv2.cvtColor(pred_face, cv2.COLOR_BGR2HSV).astype(np.float32)
            ref_hsv = cv2.cvtColor(reference_region, cv2.COLOR_BGR2HSV)
            
            pred_mean = np.mean(pred_hsv, axis=(0, 1))
            ref_mean = np.mean(ref_hsv, axis=(0, 1))
            
            # è‰²è°ƒè°ƒæ•´ï¼ˆè€ƒè™‘ç¯å½¢ç‰¹æ€§ï¼‰
            h_diff = ref_mean[0] - pred_mean[0]
            if abs(h_diff) > 90:
                h_diff = h_diff - 180 if h_diff > 0 else h_diff + 180
            
            hue_strength = min(0.5, diff_analysis['hue_diff'] / 25.0)
            saturation_strength = min(0.6, diff_analysis['saturation_diff'] / 35.0)
            
            # è°ƒæ•´å„é€šé“
            pred_hsv[:, :, 0] = (pred_hsv[:, :, 0] + h_diff * hue_strength) % 180
            pred_hsv[:, :, 1] += (ref_mean[1] - pred_mean[1]) * saturation_strength
            
            # é™åˆ¶èŒƒå›´
            pred_hsv[:, :, 1] = np.clip(pred_hsv[:, :, 1], 0, 255)
            pred_hsv[:, :, 2] = np.clip(pred_hsv[:, :, 2], 0, 255)
            
            return cv2.cvtColor(pred_hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
            
        except Exception as e:
            print(f"å¼ºåŒ–HSVè°ƒæ•´å¤±è´¥: {e}")
            return pred_face
        """åœ¨HSVç©ºé—´ä¸­æ§åˆ¶é¥±å’Œåº¦"""
        try:
            # è½¬æ¢åˆ°HSV
            matched_hsv = cv2.cvtColor(matched_face, cv2.COLOR_BGR2HSV)
            original_hsv = cv2.cvtColor(original_face, cv2.COLOR_BGR2HSV)
            
            # æ··åˆé¥±å’Œåº¦é€šé“
            original_s = original_hsv[:, :, 1].astype(np.float32)
            matched_s = matched_hsv[:, :, 1].astype(np.float32)
            
            # è®¡ç®—é¥±å’Œåº¦æ¯”ä¾‹ï¼Œé˜²æ­¢è¿‡åº¦å¢å¼º
            saturation_ratio = np.where(original_s > 0, matched_s / (original_s + 1e-6), 1.0)
            saturation_ratio = np.clip(saturation_ratio, 0.8, self.max_saturation_boost)
            
            # æ··åˆé¥±å’Œåº¦
            final_saturation = (original_s * self.saturation_preservation + 
                              matched_s * (1 - self.saturation_preservation))
            
            # åº”ç”¨é¥±å’Œåº¦é™åˆ¶
            final_saturation = np.clip(final_saturation, 0, 255)
            matched_hsv[:, :, 1] = final_saturation.astype(np.uint8)
            
            # è½¬æ¢å›BGR
            result = cv2.cvtColor(matched_hsv, cv2.COLOR_HSV2BGR)
            
            return result
            
        except Exception as e:
            print(f"HSVé¥±å’Œåº¦æ§åˆ¶å¤±è´¥: {e}")
            return matched_face
    
    def _analyze_face_colors(self, face_image: np.ndarray) -> dict:
        """åˆ†æé¢éƒ¨é¢œè‰²ç‰¹å¾"""
        # è½¬æ¢åˆ°å¤šä¸ªé¢œè‰²ç©ºé—´
        lab = cv2.cvtColor(face_image, cv2.COLOR_BGR2LAB)
        hsv = cv2.cvtColor(face_image, cv2.COLOR_BGR2HSV)
        yuv = cv2.cvtColor(face_image, cv2.COLOR_BGR2YUV)
        
        # è®¡ç®—é¢œè‰²ç»Ÿè®¡
        colors = {
            'bgr_mean': np.mean(face_image, axis=(0, 1)),
            'bgr_std': np.std(face_image, axis=(0, 1)),
            'lab_mean': np.mean(lab, axis=(0, 1)),
            'lab_std': np.std(lab, axis=(0, 1)),
            'hsv_mean': np.mean(hsv, axis=(0, 1)),
            'hsv_std': np.std(hsv, axis=(0, 1)),
            'yuv_mean': np.mean(yuv, axis=(0, 1)),
            'yuv_std': np.std(yuv, axis=(0, 1)),
            'brightness': np.mean(lab[:, :, 0]),
            'saturation': np.mean(hsv[:, :, 1]),
        }
        
        return colors

    def _analyze_background_colors(self, frame: np.ndarray, bbox: Tuple[int, int, int, int]) -> dict:
        """åˆ†æèƒŒæ™¯é¢œè‰²ç‰¹å¾"""
        y1, y2, x1, x2 = bbox
        h, w = frame.shape[:2]
        
        # è·å–å¤šä¸ªå‚è€ƒåŒºåŸŸ
        regions = []
        
        # é¢éƒ¨å‘¨å›´åŒºåŸŸ
        margin = min(30, (y2-y1)//3, (x2-x1)//3)
        
        # ä¸Šæ–¹åŒºåŸŸ
        if y1 >= margin:
            regions.append(frame[max(0, y1-margin):y1, x1:x2])
        
        # ä¸‹æ–¹åŒºåŸŸ
        if y2 + margin < h:
            regions.append(frame[y2:min(h, y2+margin), x1:x2])
        
        # å·¦ä¾§åŒºåŸŸ
        if x1 >= margin:
            regions.append(frame[y1:y2, max(0, x1-margin):x1])
        
        # å³ä¾§åŒºåŸŸ
        if x2 + margin < w:
            regions.append(frame[y1:y2, x2:min(w, x2+margin)])
        
        # åˆå¹¶æ‰€æœ‰åŒºåŸŸ
        if regions:
            combined_region = np.vstack([r.reshape(-1, 3) for r in regions if r.size > 0])
            
            # è½¬æ¢åˆ°å¤šä¸ªé¢œè‰²ç©ºé—´
            lab = cv2.cvtColor(combined_region.reshape(1, -1, 3), cv2.COLOR_BGR2LAB).reshape(-1, 3)
            hsv = cv2.cvtColor(combined_region.reshape(1, -1, 3), cv2.COLOR_BGR2HSV).reshape(-1, 3)
            yuv = cv2.cvtColor(combined_region.reshape(1, -1, 3), cv2.COLOR_BGR2YUV).reshape(-1, 3)
            
            colors = {
                'bgr_mean': np.mean(combined_region, axis=0),
                'bgr_std': np.std(combined_region, axis=0),
                'lab_mean': np.mean(lab, axis=0),
                'lab_std': np.std(lab, axis=0),
                'hsv_mean': np.mean(hsv, axis=0),
                'hsv_std': np.std(hsv, axis=0),
                'yuv_mean': np.mean(yuv, axis=0),
                'yuv_std': np.std(yuv, axis=0),
                'brightness': np.mean(lab[:, 0]),
                'saturation': np.mean(hsv[:, 1]),
            }
        else:
            # ä½¿ç”¨æ•´ä¸ªå¸§ä½œä¸ºå‚è€ƒ
            frame_colors = self._analyze_face_colors(frame)
            colors = frame_colors
        
        return colors

    def _intelligent_color_mapping(self, face: np.ndarray, face_colors: dict, bg_colors: dict, strength: float) -> np.ndarray:
        """æ™ºèƒ½é¢œè‰²æ˜ å°„"""
        # åœ¨LABç©ºé—´è¿›è¡Œä¸»è¦è°ƒæ•´
        face_lab = cv2.cvtColor(face, cv2.COLOR_BGR2LAB).astype(np.float32)
        
        # äº®åº¦è°ƒæ•´
        brightness_diff = bg_colors['brightness'] - face_colors['brightness']
        brightness_adjustment = brightness_diff * strength * 0.3  # å‡å°‘äº®åº¦è°ƒæ•´å¼ºåº¦
        face_lab[:, :, 0] = np.clip(face_lab[:, :, 0] + brightness_adjustment, 0, 255)
        
        # è‰²å½©è°ƒæ•´ (Aå’ŒBé€šé“)
        for i in [1, 2]:  # A, Bé€šé“
            color_diff = bg_colors['lab_mean'][i] - face_colors['lab_mean'][i]
            color_adjustment = color_diff * strength * 0.5  # é€‚åº¦çš„è‰²å½©è°ƒæ•´
            face_lab[:, :, i] = np.clip(face_lab[:, :, i] + color_adjustment, 0, 255)
        
        # è½¬æ¢å›BGR
        mapped_bgr = cv2.cvtColor(face_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
        
        # åœ¨HSVç©ºé—´è¿›è¡Œé¥±å’Œåº¦è°ƒæ•´
        face_hsv = cv2.cvtColor(mapped_bgr, cv2.COLOR_BGR2HSV).astype(np.float32)
        
        # é¥±å’Œåº¦è°ƒæ•´
        saturation_diff = bg_colors['saturation'] - face_colors['saturation']
        saturation_adjustment = saturation_diff * strength * 0.4
        face_hsv[:, :, 1] = np.clip(face_hsv[:, :, 1] + saturation_adjustment, 0, 255)
        
        # è½¬æ¢å›BGR
        result = cv2.cvtColor(face_hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
        
        return result

    def _edge_color_blending(self, face: np.ndarray, frame: np.ndarray, bbox: Tuple[int, int, int, int]) -> np.ndarray:
        """è¾¹ç¼˜é¢œè‰²èåˆ"""
        y1, y2, x1, x2 = bbox
        
        # åˆ›å»ºè¾¹ç¼˜æƒé‡æ©ç 
        h, w = face.shape[:2]
        edge_width = min(15, h//8, w//8)
        
        # åˆ›å»ºè·ç¦»å˜æ¢æ©ç 
        mask = np.ones((h, w), dtype=np.float32)
        mask[:edge_width, :] = 0
        mask[-edge_width:, :] = 0
        mask[:, :edge_width] = 0
        mask[:, -edge_width:] = 0
        
        # è·ç¦»å˜æ¢
        dist_transform = cv2.distanceTransform((mask > 0).astype(np.uint8), cv2.DIST_L2, 5)
        edge_mask = np.clip(dist_transform / edge_width, 0, 1)
        
        # æ‰©å±•åˆ°3é€šé“
        edge_mask_3d = np.stack([edge_mask] * 3, axis=2)
        
        # è·å–å¯¹åº”çš„åŸå§‹åŒºåŸŸ
        original_region = frame[y1:y2, x1:x2]
        
        # è¾¹ç¼˜èåˆ
        blended = face * edge_mask_3d + original_region * (1 - edge_mask_3d)
        
        return blended.astype(np.uint8)
    
    def _edge_color_blending_gentle(self, face: np.ndarray, frame: np.ndarray, bbox: Tuple[int, int, int, int]) -> np.ndarray:
        """æ¸©å’Œçš„è¾¹ç¼˜é¢œè‰²èåˆ - å‡å°‘å¼ºåº¦"""
        y1, y2, x1, x2 = bbox
        
        # åˆ›å»ºæ›´æ¸©å’Œçš„è¾¹ç¼˜æƒé‡æ©ç 
        h, w = face.shape[:2]
        edge_width = min(10, h//12, w//12)  # å‡å°‘è¾¹ç¼˜å®½åº¦
        
        # åˆ›å»ºè·ç¦»å˜æ¢æ©ç 
        mask = np.ones((h, w), dtype=np.float32)
        mask[:edge_width, :] = 0
        mask[-edge_width:, :] = 0
        mask[:, :edge_width] = 0
        mask[:, -edge_width:] = 0
        
        # è·ç¦»å˜æ¢
        dist_transform = cv2.distanceTransform((mask > 0).astype(np.uint8), cv2.DIST_L2, 5)
        edge_mask = np.clip(dist_transform / edge_width, 0, 1)
        
        # åº”ç”¨æ›´å¹³æ»‘çš„è¿‡æ¸¡
        edge_mask = np.power(edge_mask, 0.7)  # ä½¿è¿‡æ¸¡æ›´å¹³æ»‘
        
        # æ‰©å±•åˆ°3é€šé“
        edge_mask_3d = np.stack([edge_mask] * 3, axis=2)
        
        # è·å–å¯¹åº”çš„åŸå§‹åŒºåŸŸ
        original_region = frame[y1:y2, x1:x2]
        
        # æ¸©å’Œçš„è¾¹ç¼˜èåˆ
        blended = face * edge_mask_3d + original_region * (1 - edge_mask_3d)
        
        return blended.astype(np.uint8)

    def _skin_tone_naturalization(self, face: np.ndarray) -> np.ndarray:
        """è‚¤è‰²è‡ªç„¶åŒ–å¤„ç†"""
        # è½¬æ¢åˆ°YUVç©ºé—´è¿›è¡Œè‚¤è‰²è°ƒæ•´
        yuv = cv2.cvtColor(face, cv2.COLOR_BGR2YUV).astype(np.float32)
        
        # è‚¤è‰²èŒƒå›´è°ƒæ•´
        # Yé€šé“ - äº®åº¦ä¿æŒ
        # Ué€šé“ - å‡å°‘è“è‰²åç§»
        # Vé€šé“ - å‡å°‘çº¢è‰²åç§»
        
        # è½»å¾®è°ƒæ•´UVé€šé“ï¼Œä½¿è‚¤è‰²æ›´è‡ªç„¶
        yuv[:, :, 1] = np.clip(yuv[:, :, 1] * 0.95, 0, 255)  # å‡å°‘è“è‰²
        yuv[:, :, 2] = np.clip(yuv[:, :, 2] * 0.98, 0, 255)  # å‡å°‘çº¢è‰²
        
        # è½¬æ¢å›BGR
        result = cv2.cvtColor(yuv.astype(np.uint8), cv2.COLOR_YUV2BGR)
        
        return result
    
    def _skin_tone_naturalization_gentle(self, face: np.ndarray) -> np.ndarray:
        """æ¸©å’Œçš„è‚¤è‰²è‡ªç„¶åŒ–å¤„ç† - å‡å°‘è°ƒæ•´å¼ºåº¦"""
        # è½¬æ¢åˆ°YUVç©ºé—´è¿›è¡Œè‚¤è‰²è°ƒæ•´
        yuv = cv2.cvtColor(face, cv2.COLOR_BGR2YUV).astype(np.float32)
        
        # æ›´æ¸©å’Œçš„è‚¤è‰²è°ƒæ•´
        # Yé€šé“ - äº®åº¦ä¿æŒ
        # Ué€šé“ - è½»å¾®å‡å°‘è“è‰²åç§»
        # Vé€šé“ - è½»å¾®å‡å°‘çº¢è‰²åç§»
        
        # éå¸¸è½»å¾®çš„è°ƒæ•´UVé€šé“
        yuv[:, :, 1] = np.clip(yuv[:, :, 1] * 0.98, 0, 255)  # è½»å¾®å‡å°‘è“è‰²
        yuv[:, :, 2] = np.clip(yuv[:, :, 2] * 0.99, 0, 255)  # è½»å¾®å‡å°‘çº¢è‰²
        
        # è½¬æ¢å›BGR
        result = cv2.cvtColor(yuv.astype(np.uint8), cv2.COLOR_YUV2BGR)
        
        return result
    
    def _compensate_lighting_gentle(self, pred_face: np.ndarray, original_frame: np.ndarray, 
                                  bbox: Tuple[int, int, int, int]) -> np.ndarray:
        """æ¸©å’Œçš„å…‰ç…§è¡¥å¿ - å‡å°‘å¯¹æ¯”åº¦å¢å¼º"""
        try:
            y1, y2, x1, x2 = bbox
            
            # è®¡ç®—å‘¨å›´åŒºåŸŸçš„å¹³å‡äº®åº¦
            margin = min(15, (y2-y1)//6, (x2-x1)//6)
            
            surrounding_regions = []
            
            # ä¸Šæ–¹
            if y1 >= margin:
                surrounding_regions.append(original_frame[y1-margin:y1, x1:x2])
            
            # ä¸‹æ–¹
            if y2 + margin < original_frame.shape[0]:
                surrounding_regions.append(original_frame[y2:y2+margin, x1:x2])
            
            # å·¦ä¾§
            if x1 >= margin:
                surrounding_regions.append(original_frame[y1:y2, x1-margin:x1])
            
            # å³ä¾§
            if x2 + margin < original_frame.shape[1]:
                surrounding_regions.append(original_frame[y1:y2, x2:x2+margin])
            
            if not surrounding_regions:
                return pred_face
            
            # è®¡ç®—å‘¨å›´äº®åº¦
            surrounding_brightness = np.mean([np.mean(cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)) 
                                            for region in surrounding_regions])
            
            # è®¡ç®—é¢éƒ¨äº®åº¦
            face_brightness = np.mean(cv2.cvtColor(pred_face, cv2.COLOR_BGR2GRAY))
            
            # æ¸©å’Œçš„å…‰ç…§è¡¥å¿
            if abs(surrounding_brightness - face_brightness) > self.brightness_threshold:
                brightness_ratio = surrounding_brightness / (face_brightness + 1e-6)
                # æ›´ä¿å®ˆçš„è°ƒæ•´èŒƒå›´
                brightness_ratio = np.clip(brightness_ratio, 0.85, self.max_brightness_adjustment)
                
                compensated = pred_face.astype(np.float32) * brightness_ratio
                compensated = np.clip(compensated, 0, 255).astype(np.uint8)
                
                return compensated
            
            return pred_face
            
        except Exception as e:
            print(f"å…‰ç…§è¡¥å¿å¤±è´¥: {e}")
            return pred_face
class AdvancedFaceBlending:
    """é«˜çº§é¢éƒ¨èåˆç±» - å…¼å®¹æ€§åŒ…è£…å™¨"""
    
    def __init__(self):
        self.improved_blender = ImprovedFaceBlending()
        self.fast_blender = FastFaceBlending()
    
    def blend_face(self, *args, **kwargs):
        """
        æ™ºèƒ½é¢éƒ¨èåˆ - è‡ªåŠ¨æ£€æµ‹å‚æ•°æ ¼å¼
        
        æ”¯æŒä¸¤ç§è°ƒç”¨æ ¼å¼:
        1. lipreal384æ ¼å¼: blend_face(pred_frame, original_frame, bbox)
        2. ä¼ ç»Ÿæ ¼å¼: blend_face(source_face, target_face, landmarks)
        """
        try:
            # æ£€æµ‹è°ƒç”¨æ ¼å¼
            if len(args) >= 3:
                # æ£€æŸ¥ç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯å¦ä¸ºbbox (tuple/list of 4 numbers)
                third_arg = args[2]
                if (isinstance(third_arg, (tuple, list)) and 
                    len(third_arg) == 4 and 
                    all(isinstance(x, (int, float)) for x in third_arg)):
                    
                    # lipreal384æ ¼å¼: (pred_frame, original_frame, bbox)
                    pred_frame, original_frame, bbox = args[:3]
                    feather_amount = kwargs.get('feather_amount', 0.8)
                    
                    # ä½¿ç”¨æ”¹è¿›çš„èåˆç®—æ³•
                    result = self.improved_blender.blend_face(
                        pred_frame, original_frame, bbox, feather_amount
                    )
                    
                    if result is not None:
                        return result
                    else:
                        # å¤±è´¥æ—¶å›é€€åˆ°ç®€å•æ›¿æ¢
                        return self._fallback_blend(pred_frame, original_frame, bbox)
                
                else:
                    # ä¼ ç»Ÿæ ¼å¼: (source_face, target_face, landmarks)
                    source_face, target_face = args[:2]
                    landmarks = args[2] if len(args) > 2 else None
                    feather_amount = kwargs.get('feather_amount', 0.8)
                    
                    # ä½¿ç”¨å¿«é€Ÿèåˆ
                    return self.fast_blender.blend_face_fast(
                        source_face, target_face, landmarks, feather_amount
                    )
            
            # å‚æ•°ä¸è¶³ï¼Œè¿”å›None
            return None
            
        except Exception as e:
            print(f"èåˆè¿‡ç¨‹å‡ºé”™: {e}")
            # å°è¯•ç®€å•å›é€€
            if len(args) >= 2:
                return args[1]  # è¿”å›åŸå§‹å¸§
            return None
    
    def _fallback_blend(self, pred_frame, original_frame, bbox):
        """ç®€å•å›é€€èåˆæ–¹æ³•"""
        try:
            y1, y2, x1, x2 = bbox
            result = original_frame.copy()
            
            # è°ƒæ•´å°ºå¯¸å¹¶ç›´æ¥æ›¿æ¢
            target_width = x2 - x1
            target_height = y2 - y1
            resized_pred = cv2.resize(pred_frame, (target_width, target_height))
            
            result[y1:y2, x1:x2] = resized_pred
            return result
            
        except Exception as e:
            print(f"å›é€€èåˆå¤±è´¥: {e}")
            return original_frame

# å…¨å±€å®ä¾‹
fast_face_blender = FastFaceBlending()
advanced_face_blender = AdvancedFaceBlending()

def get_face_blender(enable_poisson=False, enable_color_matching=False,
                     enable_edge_smoothing=True, enable_noise_reduction=True):
    """è·å–é¢éƒ¨èåˆå™¨å®ä¾‹
    
    Args:
        enable_poisson: å¯ç”¨æ³Šæ¾èåˆ (é»˜è®¤: False)
        enable_color_matching: å¯ç”¨é¢œè‰²åŒ¹é… (é»˜è®¤: False)
        enable_edge_smoothing: å¯ç”¨è¾¹ç¼˜å¹³æ»‘ (é»˜è®¤: True)
        enable_noise_reduction: å¯ç”¨é™å™ª (é»˜è®¤: True)
    
    Returns:
        ImprovedFaceBlending: æ”¹è¿›çš„é¢éƒ¨èåˆå™¨å®ä¾‹
    """
    # åˆ›å»ºé…ç½®åŒ–çš„èåˆå™¨å®ä¾‹
    blender = ImprovedFaceBlending()
    
    # æ ¹æ®å‚æ•°é…ç½®åŠŸèƒ½ï¼ˆé»˜è®¤ç¦ç”¨è°ƒè‰²/æ³Šæ¾ï¼‰
    blender.enable_poisson = enable_poisson
    blender.enable_color_matching = enable_color_matching
    blender.color_match_enabled = enable_color_matching  # æ˜ å°„åˆ°å†…éƒ¨å±æ€§
    blender.enable_edge_smoothing = enable_edge_smoothing
    blender.enable_noise_reduction = enable_noise_reduction
    
    return blender

# å…¼å®¹æ€§å‡½æ•°
def blend_face(*args, **kwargs):
    """å…¨å±€èåˆå‡½æ•°"""
    return advanced_face_blender.blend_face(*args, **kwargs)

# å†å²å…¼å®¹æ€§
def match_color_histogram(source, target):
    """é¢œè‰²ç›´æ–¹å›¾åŒ¹é… - å…¼å®¹æ€§å‡½æ•°"""
    # å·²ç¦ç”¨è°ƒè‰²é€»è¾‘ï¼Œç›´æ¥è¿”å›æºå›¾ä»¥ä¿æŒé¢œè‰²ä¸€è‡´æ€§
    return source

def reduce_noise(image, strength=0.5):
    """é™å™ª - å…¼å®¹æ€§å‡½æ•°"""
    if strength > 0:
        return cv2.bilateralFilter(image, 9, 75, 75)
    return image

def enhance_edges(image, strength=0.3):
    """è¾¹ç¼˜å¢å¼º - å…¼å®¹æ€§å‡½æ•°"""
    if strength > 0:
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        enhanced = cv2.filter2D(image, -1, kernel)
        return cv2.addWeighted(image, 1-strength, enhanced, strength, 0)
    return image

if __name__ == "__main__":
    print("æ”¹è¿›çš„é¢éƒ¨èåˆæ¨¡å—å·²åŠ è½½")
    print("ä¸»è¦æ”¹è¿›:")
    print("âœ… ä»…é®ç½©èåˆ - ä¿æŒåŸè§†é¢‘é¢œè‰²ä¸€è‡´æ€§")
    print("âœ… è‡ªé€‚åº”ç¾½åŒ– - é’ˆå¯¹384æ¨¡å‹ä¼˜åŒ–")
    print("âœ… å‘åå…¼å®¹ - æ”¯æŒåŸæœ‰è°ƒç”¨æ–¹å¼")
